{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 用LSTM预测股票行情\n",
    "这里采用沪深300指数数据，时间跨度为2010-10-10至今，选择每天最高价格。假设当天最高价依赖当天的前n天（如30天）的沪深300的最高价。用LSTM模型来捕捉最高价的时序信息，通过训练模型，使之学会用前n天的最高价，判断当天的最高价（作为训练的标签值）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.1 导入数据\n",
    "这里使用tushare来下载沪深300指数数据。可以用pip 安装tushare。\n",
    "### <font color = blue>注意：目前下载沪深300指数数据需要注册及需要一定积分，如果你无法下载数据，可以跳过这步，直接使用我们已下载的数据包sh300.csv</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tushare as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cons = ts.get_apis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取沪深指数(000300)的信息，包括交易日期（datetime）、开盘价(open)、收盘价(close)，\n",
    "#最高价(high)、最低价(low)、成交量(vol)、成交金额(amount)、涨跌幅(p_change)\n",
    "# df = ts.bar('000300', conn=cons, asset='INDEX', start_date='2010-01-01', end_date='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna()\n",
    "# df.to_csv('sh300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('sh300.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code', 'open', 'close', 'high', 'low', 'vol', 'amount', 'p_change'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.2 数据概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>p_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2295.0</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>2295.000000</td>\n",
       "      <td>2.295000e+03</td>\n",
       "      <td>2.295000e+03</td>\n",
       "      <td>2295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>300.0</td>\n",
       "      <td>3100.514637</td>\n",
       "      <td>3103.181503</td>\n",
       "      <td>3128.213684</td>\n",
       "      <td>3073.658757</td>\n",
       "      <td>1.090221e+06</td>\n",
       "      <td>1.296155e+11</td>\n",
       "      <td>0.012397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>627.888776</td>\n",
       "      <td>628.060844</td>\n",
       "      <td>634.870454</td>\n",
       "      <td>618.306225</td>\n",
       "      <td>9.284048e+05</td>\n",
       "      <td>1.268450e+11</td>\n",
       "      <td>1.483714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>300.0</td>\n",
       "      <td>2079.870000</td>\n",
       "      <td>2086.970000</td>\n",
       "      <td>2118.790000</td>\n",
       "      <td>2023.170000</td>\n",
       "      <td>2.190120e+05</td>\n",
       "      <td>2.120044e+10</td>\n",
       "      <td>-8.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300.0</td>\n",
       "      <td>2534.185000</td>\n",
       "      <td>2534.185000</td>\n",
       "      <td>2558.015000</td>\n",
       "      <td>2514.585000</td>\n",
       "      <td>5.634255e+05</td>\n",
       "      <td>6.092613e+10</td>\n",
       "      <td>-0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>300.0</td>\n",
       "      <td>3160.800000</td>\n",
       "      <td>3165.910000</td>\n",
       "      <td>3193.820000</td>\n",
       "      <td>3134.380000</td>\n",
       "      <td>8.055400e+05</td>\n",
       "      <td>9.127102e+10</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300.0</td>\n",
       "      <td>3484.665000</td>\n",
       "      <td>3486.080000</td>\n",
       "      <td>3510.940000</td>\n",
       "      <td>3461.215000</td>\n",
       "      <td>1.202926e+06</td>\n",
       "      <td>1.382787e+11</td>\n",
       "      <td>0.705000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>300.0</td>\n",
       "      <td>5379.470000</td>\n",
       "      <td>5353.750000</td>\n",
       "      <td>5380.430000</td>\n",
       "      <td>5283.090000</td>\n",
       "      <td>6.864391e+06</td>\n",
       "      <td>9.494980e+11</td>\n",
       "      <td>6.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code         open        close         high          low  \\\n",
       "count  2295.0  2295.000000  2295.000000  2295.000000  2295.000000   \n",
       "mean    300.0  3100.514637  3103.181503  3128.213684  3073.658757   \n",
       "std       0.0   627.888776   628.060844   634.870454   618.306225   \n",
       "min     300.0  2079.870000  2086.970000  2118.790000  2023.170000   \n",
       "25%     300.0  2534.185000  2534.185000  2558.015000  2514.585000   \n",
       "50%     300.0  3160.800000  3165.910000  3193.820000  3134.380000   \n",
       "75%     300.0  3484.665000  3486.080000  3510.940000  3461.215000   \n",
       "max     300.0  5379.470000  5353.750000  5380.430000  5283.090000   \n",
       "\n",
       "                vol        amount     p_change  \n",
       "count  2.295000e+03  2.295000e+03  2295.000000  \n",
       "mean   1.090221e+06  1.296155e+11     0.012397  \n",
       "std    9.284048e+05  1.268450e+11     1.483714  \n",
       "min    2.190120e+05  2.120044e+10    -8.750000  \n",
       "25%    5.634255e+05  6.092613e+10    -0.650000  \n",
       "50%    8.055400e+05  9.127102e+10     0.020000  \n",
       "75%    1.202926e+06  1.382787e+11     0.705000  \n",
       "max    6.864391e+06  9.494980e+11     6.710000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.3 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "LR = 0.001\n",
    "EPOCH = 200\n",
    "batch_size=20\n",
    "train_end =-600\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过一个序列来生成一个 31 * (count(*)-train_end) 矩阵（用于处理时序的数据）\n",
    "# 其中最后一列维标签数据。就是把当天的前n天作为参数，当天的数据作为label\n",
    "\n",
    "def generate_data_by_n_days(series, n, index=False):\n",
    "    if len(series) <= n:\n",
    "        raise Exception(\"The Length of series is %d, while affect by (n=%d).\" % (len(series), n))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    l = series.tolist()\n",
    "    for i in range(n):\n",
    "        print(f\"len df: {len(df)}\")\n",
    "        print(f\"len l: {len(l)}\")\n",
    "        df['c%d' % i] = l[i:-(n - 1)]  \n",
    "\n",
    "    df['y'] = l[n:]\n",
    "\n",
    "    if index:\n",
    "        df.index = series.index[n:]\n",
    "\n",
    "    return df\n",
    "\n",
    "# 参数n与上相同。train_end 表示的是后面多少个数据作为测试集。\n",
    "def readData(column='high', n=30, all_too=True, index=False, train_end=-500):\n",
    "    df = pd.read_csv(\"sh300.csv\", index_col=0)\n",
    "\n",
    "    #以日期为索引\n",
    "    df.index = list(map(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"), df.index))\n",
    "    #获取每天的最高价\n",
    "    df_column = df[column].copy()\n",
    "    #拆分为训练集和测试集\n",
    "    df_column_train, df_column_test = df_column[:train_end], df_column[train_end - n:]\n",
    "    #生成训练数据\n",
    "    df_generate_train = generate_data_by_n_days(df_column_train, n, index=index)\n",
    "    if all_too:\n",
    "        return df_generate_train, df_column, df.index.tolist()\n",
    "\n",
    "    return df_generate_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.4 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=64,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        r_out, (h_n, h_c) = self.lstm(x, None) #None即隐层状态用0初始化\n",
    "        out = self.out(r_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyTrainSet(Dataset):\n",
    "    def __init__(self, data):        \n",
    "        self.data, self.label = data[:, :-1].float(), data[:, -1].float()\n",
    "             \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.5 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len df: 0\n",
      "len l: 1695\n",
      "len df: 1666\n",
      "len l: 1695\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1665) does not match length of index (1666)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m register_matplotlib_converters()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 获取训练数据、原始数据、索引等信息\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df, df_all, df_index \u001b[39m=\u001b[39m readData(\u001b[39m'\u001b[39;49m\u001b[39mhigh\u001b[39;49m\u001b[39m'\u001b[39;49m, n\u001b[39m=\u001b[39;49mn, train_end\u001b[39m=\u001b[39;49mtrain_end)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#可视化原高价数据\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df_all \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(df_all\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[1;32m/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb Cell 19\u001b[0m in \u001b[0;36mreadData\u001b[0;34m(column, n, all_too, index, train_end)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m df_column_train, df_column_test \u001b[39m=\u001b[39m df_column[:train_end], df_column[train_end \u001b[39m-\u001b[39m n:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#生成训练数据\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m df_generate_train \u001b[39m=\u001b[39m generate_data_by_n_days(df_column_train, n, index\u001b[39m=\u001b[39;49mindex)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m all_too:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df_generate_train, df_column, df\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[1;32m/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb Cell 19\u001b[0m in \u001b[0;36mgenerate_data_by_n_days\u001b[0;34m(series, n, index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlen df: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlen l: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(l)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     df[\u001b[39m'\u001b[39;49m\u001b[39mc\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m i] \u001b[39m=\u001b[39m l[i:\u001b[39m-\u001b[39m(n \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)]  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m l[n:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_04_lstm/py_07_04_lstm_pytorch.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m index:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py:3607\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3604\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3605\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3606\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3607\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py:3779\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3770\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3771\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3772\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3777\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3778\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3779\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   3781\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3782\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   3783\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3784\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3785\u001b[0m     ):\n\u001b[1;32m   3786\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3787\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/frame.py:4504\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4501\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4503\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4504\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4505\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/common.py:531\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 531\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1665) does not match length of index (1666)"
     ]
    }
   ],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# 获取训练数据、原始数据、索引等信息\n",
    "df, df_all, df_index = readData('high', n=n, train_end=train_end)\n",
    "\n",
    "#可视化原高价数据\n",
    "df_all = np.array(df_all.tolist())\n",
    "plt.plot(df_index, df_all, label='real-data')\n",
    "plt.legend(loc='upper right')  \n",
    "\n",
    "#对数据进行预处理，规范化及转换为Tensor\n",
    "df_numpy = np.array(df)\n",
    "\n",
    "df_numpy_mean = np.mean(df_numpy)\n",
    "df_numpy_std = np.std(df_numpy)\n",
    "\n",
    "df_numpy = (df_numpy - df_numpy_mean) / df_numpy_std\n",
    "df_tensor = torch.Tensor(df_numpy)\n",
    "\n",
    "trainset = MyTrainSet(df_tensor)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录损失值，并用tensorboardx在web上展示\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='logs')\n",
    "\n",
    "rnn = LSTMModel(n).to(device)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)  \n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for step in range(EPOCH):\n",
    "    for tx, ty in trainloader:\n",
    "        tx=tx.to(device)\n",
    "        ty=ty.to(device)\n",
    "        #在第1个维度上添加一个维度为1的维度，形状变为[batch,seq_len,input_size]\n",
    "        output = rnn(torch.unsqueeze(tx, dim=1)).to(device)\n",
    "        loss = loss_func(torch.squeeze(output), ty)\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "    writer.add_scalar('sh300_loss', loss, step)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8.6 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data_train = []\n",
    "generate_data_test = []\n",
    "\n",
    "test_index = len(df_all) + train_end\n",
    "\n",
    "df_all_normal = (df_all - df_numpy_mean) / df_numpy_std\n",
    "df_all_normal_tensor = torch.Tensor(df_all_normal)\n",
    "for i in range(n, len(df_all)):\n",
    "    x = df_all_normal_tensor[i - n:i].to(device)\n",
    "    #rnn的输入必须是3维，故需添加两个1维的维度，最后成为[1,1,input_size]\n",
    "    x = torch.unsqueeze(torch.unsqueeze(x, dim=0), dim=0)\n",
    "    \n",
    "    y = rnn(x).to(device)\n",
    "    if i < test_index:\n",
    "        generate_data_train.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)\n",
    "    else:\n",
    "        generate_data_test.append(torch.squeeze(y).detach().cpu().numpy() * df_numpy_std + df_numpy_mean)\n",
    "plt.plot(df_index[n:train_end], generate_data_train, label='generate_train')\n",
    "plt.plot(df_index[train_end:], generate_data_test, label='generate_test')\n",
    "plt.plot(df_index[train_end:], df_all[train_end:], label='real-data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(df_index[train_end:-500], df_all[train_end:-500], label='real-data')\n",
    "plt.plot(df_index[train_end:-500], generate_data_test[-600:-500], label='generate_test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
