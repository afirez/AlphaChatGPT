{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无梯度强化学习：使用 Numpy 进行神经进化！\n",
    "\n",
    "我们能否在没有反向传播的情况下解决简单的强化学习环境？"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经进化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简介\n",
    "\n",
    "如果我告诉你，你可以在训练神经网络时，从未计算过梯度，只使用正向传播，你会怎么想？这就是神经进化的魔力所在！而且，我将展示所有这些都可以轻松地只使用 Numpy 完成！在学习统计学时，你会了解许多关于基于梯度的方法，但不久前我读了一篇由优步 AI 团队撰写的非常有趣的文章，他们展示了一个简单的遗传算法在解决 Atari 游戏方面，在墙上时钟时间上竟然能与最复杂的基于梯度的强化学习方法相媲美。我在下面附上了文章链接，如果你对强化学习感兴趣，我强烈建议你阅读一下。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是神经进化？\n",
    "\n",
    "首先，对于那些尚不了解的人，神经进化描述了将进化和/或遗传算法应用于训练神经网络的结构和/或权重的过程，作为一种无梯度的替代方法！在这里，我们将使用一个极其简单的神经进化案例，仅使用固定拓扑网络，并专注于优化权重和偏差。神经进化的过程可以通过四个基本步骤来定义，这些步骤会重复进行，直到达到收敛，起始于一组随机生成的网络。\n",
    "\n",
    "1. 评估种群的适应性\n",
    "2. 选择适应性最强的个体进行繁殖\n",
    "3. 使用适应性最强网络的副本进行再生\n",
    "4. 对网络权重引入正态分布的突变\n",
    "   \n",
    "哇，这看起来相当简单！让我们稍微解释一些术语：\n",
    "\n",
    "- 适应性：这仅仅描述了网络在特定任务上的表现如何，并允许我们确定哪些网络进行繁殖。请注意，由于进化算法是一种非凸优化形式，因此可以与任何损失函数一起使用，而不受其可微性（或缺乏可微性）的限制。\n",
    "\n",
    "- 突变：这可能是最容易理解的部分！为了让我们的子网络得以改进，我们必须对网络权重引入随机变化，通常是从均匀或正态分布中抽取的。突变可以有许多不同的形式：平移突变（将参数乘以随机数）、交换突变（将参数替换为随机数）、符号突变（改变参数的符号）等等。在这里，我们只会使用简单的加性突变，但在这方面有很大的创造空间！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经进化的优势\n",
    "\n",
    "我们还应该考虑神经进化建模的理论优势。首先，我们只需要使用网络的正向传播，因为我们只需要计算损失来确定哪些网络进行繁殖。这样做的影响是显而易见的，反向传播通常是最耗时的！其次，进化算法在足够迭代次数的情况下保证能找到损失表面的全局最小值，而凸梯度优化方法可能会陷入局部最小值。最后，更复杂的神经进化形式不仅允许我们优化网络的权重，还可以优化网络的结构本身！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么不总是使用神经进化呢？\n",
    "\n",
    "这实际上是一个复杂的问题，但归根结底，当有足够的梯度信息可用时，精确梯度下降方法更有效。这意味着损失表面越凸，你就越希望使用类似 SGD 的解析方法，而不是遗传算法。因此，在监督环境中很少会使用遗传算法，因为通常有足够的梯度信息可用，传统的梯度下降方法会表现得非常好。然而，如果你在强化学习环境中工作，或者在具有不规则损失曲面或低凸性（如顺序 GAN）的情况下工作，那么神经进化提供了一个可行的替代方案！事实上，最近的许多研究发现，在这些设置中，按参数进行神经进化模型可以取得更好的效果。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 现在让我们开始吧！\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载库\n",
    "\n",
    "正如在介绍中所述，我们将尝试仅使用 numpy 来完成这个项目，只定义我们所需的辅助函数！是的，我知道，还加载了 gym，但仅用于环境 ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于数据\n",
    "\n",
    "我们将使用 gym 中经典的 CartPole 环境来测试我们的网络。目标是通过左右移动来看网络能够将杆保持站立的时间有多长。作为一个强化学习任务，神经进化方法应该很适合！我们的网络将以4个观测作为输入，并将左或右作为动作输出。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 辅助函数\n",
    "\n",
    "我们首先会定义一些辅助函数来设置我们的网络。首先是 relu 激活函数，我们将它作为隐藏层的激活函数，然后是 softmax 函数，用于网络的输出，以获取网络输出的概率估计！最后，我们需要定义一个函数，用于生成响应向量的 one-hot 编码，以便在计算分类交叉熵时使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.exp(x - np.max(x))\n",
    "    x[x == 0] = 1e-15\n",
    "    return np.array(x / x.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两个函数会帮助我们在后续的代码中进行网络的激活函数计算。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义我们的网络类\n",
    "\n",
    "接下来是有趣的部分！首先，我们将为种群内的个体网络定义一个类。我们需要定义一个初始化方法，该方法会随机分配权重和偏差，并将网络结构作为输入；一个预测方法，以便在给定输入时获取概率；最后一个评估方法，它返回给定输入和响应的网络的分类交叉熵！再次强调，我们只会使用我们定义的函数或来自 numpy 的函数。注意，初始化方法也可以接受另一个网络作为输入，这是我们将在代际之间执行突变的方式！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    \n",
    "    def __init__(self, n_units=None, copy_network=None, var=0.02, episodes=50, max_episode_length=200):\n",
    "        # Testing if we need to copy a network\n",
    "        if copy_network is None:\n",
    "            # Saving attributes\n",
    "            self.n_units = n_units\n",
    "            # Initializing empty lists to hold matrices\n",
    "            weights = []\n",
    "            biases = []\n",
    "            # Populating the lists\n",
    "            for i in range(len(n_units)-1):\n",
    "                weights.append(np.random.normal(loc=0,scale=1,size=(n_units[i],n_units[i+1])))\n",
    "                biases.append(np.zeros(n_units[i+1]))\n",
    "            # Creating dictionary of parameters\n",
    "            self.params = {'weights':weights,'biases':biases}\n",
    "        else:\n",
    "            # Copying over elements\n",
    "            self.n_units = copy_network.n_units\n",
    "            self.params = {'weights':np.copy(copy_network.params['weights']),\n",
    "                          'biases':np.copy(copy_network.params['biases'])}\n",
    "            # Mutating the weights\n",
    "            self.params['weights'] = [x+np.random.normal(loc=0,scale=var,size=x.shape) for x in self.params['weights']]\n",
    "            self.params['biases'] = [x+np.random.normal(loc=0,scale=var,size=x.shape) for x in self.params['biases']]\n",
    "            \n",
    "    def act(self, X):\n",
    "        # Grabbing weights and biases\n",
    "        weights = self.params['weights']\n",
    "        biases = self.params['biases']\n",
    "        # First propgating inputs\n",
    "        a = relu((X@weights[0])+biases[0])\n",
    "        # Now propogating through every other layer\n",
    "        for i in range(1,len(weights)):\n",
    "            a = relu((a@weights[i])+biases[i])\n",
    "        # Getting probabilities by using the softmax function\n",
    "        probs = softmax(a)\n",
    "        return np.argmax(probs)\n",
    "        \n",
    "    # Defining the evaluation method\n",
    "    def evaluate(self, episodes, max_episode_length, render_env, record):\n",
    "        # Creating empty list for rewards\n",
    "        rewards = []\n",
    "        # First we need to set up our gym environment\n",
    "        env = gym.make('CartPole-v0')\n",
    "        # Recording video if we need to \n",
    "        if record is True:\n",
    "            env = gym.wrappers.Monitor(env, \"recording\")\n",
    "        # Increasing max steps\n",
    "        env._max_episode_steps = 1e20\n",
    "        for i_episode in range(episodes):\n",
    "            observation = env.reset()\n",
    "            for t in range(max_episode_length):\n",
    "                if render_env is True:\n",
    "                    env.render()\n",
    "                observation, _, done, _ = env.step(self.act(np.array(observation)))\n",
    "                if done:\n",
    "                    rewards.append(t)\n",
    "                    break\n",
    "        # Closing our environment\n",
    "        env.close()\n",
    "        # Getting our final reward\n",
    "        if len(rewards) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.array(rewards).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个类将帮助我们创建和操作神经网络，以及评估它们在 CartPole 环境中的表现。我们定义了初始化方法来随机初始化网络参数，act 方法用于执行网络的前向传播并生成动作，evaluate 方法用于评估网络在环境中的表现。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义我们的遗传算法类\n",
    "\n",
    "最后，我们需要定义一个管理种群的类，执行神经进化的四个关键步骤！我们需要三个方法。首先，初始化方法创建一组随机网络并设置属性。接下来，我们需要一个适应性方法，给定一个输入，重复执行上述步骤：首先评估网络，然后选择最适合的，创建子网络，最后突变子网络！最后，我们需要一个预测方法，以便我们可以使用该类训练的最佳网络。让我们开始测试吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticNetworks():\n",
    "    \n",
    "    # Defining our initialization method\n",
    "    def __init__(self, architecture=(4,16,2), population_size=50, generations=500, render_env=True, record=False,\n",
    "                 mutation_variance=0.02, verbose=False, print_every=1, episodes=10, max_episode_length=200):\n",
    "        # Creating our list of networks\n",
    "        self.networks = [NeuralNet(architecture) for _ in range(population_size)]\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_variance = mutation_variance\n",
    "        self.verbose = verbose\n",
    "        self.print_every = print_every\n",
    "        self.fitness = []\n",
    "        self.episodes = episodes\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.render_env = render_env\n",
    "        self.record = record\n",
    "        \n",
    "    # Defining our fitting method\n",
    "    def fit(self):\n",
    "        # Iterating over all generations\n",
    "        for i in range(self.generations):\n",
    "            # Doing our evaluations\n",
    "            rewards = np.array([x.evaluate(self.episodes, self.max_episode_length, self.render_env, self.record) for x in self.networks])\n",
    "            # Tracking best score per generation\n",
    "            self.fitness.append(np.max(rewards))\n",
    "            # Selecting the best network\n",
    "            best_network = np.argmax(rewards)\n",
    "            # Creating our child networks\n",
    "            new_networks = [NeuralNet(copy_network=self.networks[best_network], var=self.mutation_variance, max_episode_length=self.max_episode_length) for _ in range(self.population_size-1)]\n",
    "            # Setting our new networks\n",
    "            self.networks = [self.networks[best_network]] + new_networks\n",
    "            # Printing output if necessary\n",
    "            if self.verbose is True and (i % self.print_every == 0 or i == 0):\n",
    "                print('Generation:', i + 1, '| Highest Reward:', rewards.max().round(1), '| Average Reward:', rewards.mean().round(1))\n",
    "        \n",
    "        # Returning the best network\n",
    "        self.best_network = self.networks[best_network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个类将帮助我们设置并管理网络种群，执行神经进化的步骤，并训练出在 CartPole 环境中表现最好的网络。我们可以使用 fit 方法来开始训练过程。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试我们的算法！\n",
    "\n",
    "如上所述，我们将在 CartPole 问题上测试我们的网络，只使用一个包含16个节点的隐藏层，以及两个输出节点，表示向左或向右移动。我们还需要对许多回合进行平均，这样我们就不会意外地选择一个不好的网络进入下一代！我在一些试错之后选择了许多这些参数，因此你的情况可能会有所不同！此外，我们只会引入方差为0.05的突变，以免破坏网络的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/numpy/lib/function_base.py:935: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, order=order, subok=subok, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1 | Highest Reward: 1128.3 | Average Reward: 43.1\n",
      "Generation: 2 | Highest Reward: 6833.5 | Average Reward: 477.0\n",
      "Generation: 3 | Highest Reward: 5390.0 | Average Reward: 667.6\n",
      "Generation: 4 | Highest Reward: 6157.0 | Average Reward: 747.0\n",
      "Generation: 5 | Highest Reward: 8121.0 | Average Reward: 1264.6\n",
      "Finished in 569.993 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "genetic_pop = GeneticNetworks(architecture=(4,16,2),\n",
    "                                population_size=64, \n",
    "                                generations=5,\n",
    "                                episodes=15, \n",
    "                                mutation_variance=0.1,\n",
    "                                max_episode_length=10000,\n",
    "                                render_env=False,\n",
    "                                verbose=True)\n",
    "genetic_pop.fit()\n",
    "print('Finished in',round(time()-start_time,3),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码将训练一个种群的网络，并输出每代中最高和平均奖励。这个示例中，我们进行了5代训练，每代使用15个回合进行评估。训练过程可能需要一些时间，取决于你的计算机性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始随机网络\n",
    "\n",
    "首先，让我们看看一个随机初始化的网络在这个任务上的表现。显然，这里没有任何策略，杆子几乎立即倒下。请忽略下面 GIF 中的光标，Gym 的录制在 Windows 下效果不佳！\n",
    "\n",
    "![InitialNetwork](Numpy-Neuroevolution/InitialNetwork.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_network = NeuralNet(n_units=(4,16,2))\n",
    "# random_network.evaluate(episodes=1, max_episode_length=int(1e10), render_env=True, record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码会创建一个随机初始化的网络，并在 CartPole 环境中进行一次评估。你可以尝试运行这段代码，观察随机网络的表现。由于是随机策略，你会看到杆子很快就会倒下。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 经过5代训练...\n",
    "\n",
    "在仅经过5代训练后，我们可以看到我们的网络几乎已经完全掌握了 CartPole 的技巧！而且仅仅花费了约30秒的训练时间！请注意，随着进一步的训练，网络将学会几乎100%的时间内将杆保持完全站立，但目前我们只关心速度，5代训练的时间相对较短！我们应该将这视为神经进化的威力的一个很好的例子。\n",
    "\n",
    "![5 gen TrainedNetwork](Numpy-Neuroevolution/TrainedNetwork.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-20 23:18:26.890 python[75862:13917624] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fe4ff7d1810>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-20 23:18:26.891 python[75862:13917624] Warning: Expected min height of view: (<NSButton: 0x7fe500eb5630>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-20 23:18:26.896 python[75862:13917624] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fe4ff7dab50>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n",
      "2023-08-20 23:18:26.898 python[75862:13917624] Warning: Expected min height of view: (<NSPopoverTouchBarItemButton: 0x7fe500ac00f0>) to be less than or equal to 30 but got a height of 32.000000. This error will be logged once per view in violation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Lets observe our best network\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m genetic_pop\u001b[39m.\u001b[39;49mbest_network\u001b[39m.\u001b[39;49mevaluate(episodes\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, max_episode_length\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m1e10\u001b[39;49m), render_env\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, record\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32m/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb Cell 27\u001b[0m in \u001b[0;36mNeuralNet.evaluate\u001b[0;34m(self, episodes, max_episode_length, render_env, record)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_episode_length):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mif\u001b[39;00m render_env \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         env\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     observation, _, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(np\u001b[39m.\u001b[39marray(observation)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/afirez/studio/gpt/AlphaChatGPT/alphachatgpt/case_02_neuro_evaluation/neuro_evaluation.ipynb#X35sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/gym/envs/classic_control/cartpole.py:229\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcarttrans\u001b[39m.\u001b[39mset_translation(cartx, carty)\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoletrans\u001b[39m.\u001b[39mset_rotation(\u001b[39m-\u001b[39mx[\u001b[39m2\u001b[39m])\n\u001b[0;32m--> 229\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mrender(return_rgb_array\u001b[39m=\u001b[39;49mmode \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/gym/envs/classic_control/rendering.py:145\u001b[0m, in \u001b[0;36mViewer.render\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    143\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mreshape(buffer\u001b[39m.\u001b[39mheight, buffer\u001b[39m.\u001b[39mwidth, \u001b[39m4\u001b[39m)\n\u001b[1;32m    144\u001b[0m     arr \u001b[39m=\u001b[39m arr[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :, \u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]\n\u001b[0;32m--> 145\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow\u001b[39m.\u001b[39;49mflip()\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39monetime_geoms \u001b[39m=\u001b[39m []\n\u001b[1;32m    147\u001b[0m \u001b[39mreturn\u001b[39;00m arr \u001b[39mif\u001b[39;00m return_rgb_array \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misopen\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pyglet/window/cocoa/__init__.py:296\u001b[0m, in \u001b[0;36mCocoaWindow.flip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdraw_mouse_cursor()\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext:\n\u001b[0;32m--> 296\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49mflip()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pyglet/gl/cocoa.py:335\u001b[0m, in \u001b[0;36mCocoaContext.flip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflip\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_nscontext\u001b[39m.\u001b[39;49mflushBuffer()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pyglet/libs/darwin/cocoapy/runtime.py:805\u001b[0m, in \u001b[0;36mObjCBoundMethod.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m    804\u001b[0m     \u001b[39m\"\"\"Call the method with the given arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmethod(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobjc_id, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/py38/lib/python3.8/site-packages/pyglet/libs/darwin/cocoapy/runtime.py:775\u001b[0m, in \u001b[0;36mObjCMethod.__call__\u001b[0;34m(self, objc_id, *args)\u001b[0m\n\u001b[1;32m    773\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_callable()\n\u001b[1;32m    774\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 775\u001b[0m     result \u001b[39m=\u001b[39m f(objc_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselector, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    776\u001b[0m     \u001b[39m# Convert result to python type if it is a instance or class pointer.\u001b[39;00m\n\u001b[1;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestype \u001b[39m==\u001b[39m ObjCInstance:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Lets observe our best network\n",
    "genetic_pop.best_network.evaluate(episodes=3, max_episode_length=int(1e10), render_env=True, record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码会评估经过训练的最佳网络，让你观察它在 CartPole 环境中的表现。你可以尝试运行这段代码，看看经过5代训练的网络如何解决 CartPole 任务。你会发现，网络现在能够长时间地保持杆子的平衡。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来呢？\n",
    "\n",
    "显然，我们未来可以添加许多东西来进一步研究神经进化的有效性。首先，研究不同突变操作（例如交叉）的效果将是很有趣的。\n",
    "\n",
    "将来考虑切换到现代的深度学习平台，如TensorFlow或PyTorch，也是一个明智的想法。请注意，遗传算法是高度可并行化的，因为我们只需在单个设备上运行每个网络，执行一次前向传播。无需镜像权重或复杂的分布策略！因此，随着每增加一个处理单元，运行时间几乎呈线性下降。\n",
    "\n",
    "最后，我们应该在不同的强化学习任务中探索神经进化，甚至是其他情况，例如在生成对抗网络或长序列LSTM网络中难以评估梯度的情况。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 进一步阅读\n",
    "\n",
    "如果你对神经进化及其应用感兴趣，Uber在其工程博客上有一个精彩的页面，展示了神经进化在强化学习中的现代优势：\n",
    "\n",
    "[Uber Engineering Blog](https://www.uber.com/zh-US/blog/san-francisco/engineering/)\n",
    "\n",
    "该项目的源代码可以在我的公共GitHub仓库中找到：\n",
    "\n",
    "[gursky1/Numpy-Neuroevolution](https://github.com/gursky1/Numpy-Neuroevolution)\n",
    "\n",
    "这个仓库包含了你在本文中使用的神经进化代码。你可以在那里找到更多关于神经进化的信息和示例。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
