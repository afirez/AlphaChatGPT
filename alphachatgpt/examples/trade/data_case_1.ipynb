{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 DuckDB UDF 加速 Pandas\n",
    "\n",
    "[1] 使用 DuckDB UDF 加速 Pandas : https://zhuanlan.zhihu.com/p/646788236"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近需要对一批商品数据进行分析，加上前后各种数据清洗，\n",
    "\n",
    "初版程序使用 Pandas 运行耗时几个小时，中间耗时最长的是各种 groupby 后再计算。\n",
    "\n",
    "经过逐步优化，耗时减少到不到半个小时，随记录下中间的一些优化过程。\n",
    "\n",
    "其中有一个 groupby 是计算每个商品的回归系数，Mock 数据如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm # pip install statsmodels\n",
    "\n",
    "\"\"\"\n",
    "pip install statsmodels\n",
    "pip install joblib\n",
    "pip install duckdb\n",
    "pip install chdb # clickhouse-local (mac, linux)\n",
    "\"\"\"\n",
    "\n",
    "def mock(i: int):\n",
    "    nobs = 10\n",
    "    X = np.random.random((nobs, 2))\n",
    "    beta = [1, .1, .5]\n",
    "    e = np.random.random(nobs)\n",
    "    y = np.dot(sm.add_constant(X), beta) + e\n",
    "    return pd.DataFrame(X, columns=[\"x1\", \"x2\"]).assign(y=y, key=f\"c{i:0>4}\").filter([\"key\", \"x1\", \"x2\", \"y\"])\n",
    "\n",
    "\n",
    "df = pd.concat([mock(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品 c1, c2, ...，自变量 x1 、x2 ，因变量 y，分别计算每个商品的回归系数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0000</td>\n",
       "      <td>0.320411</td>\n",
       "      <td>0.914019</td>\n",
       "      <td>1.758490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0000</td>\n",
       "      <td>0.421961</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>1.095975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0000</td>\n",
       "      <td>0.472938</td>\n",
       "      <td>0.205749</td>\n",
       "      <td>1.981890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0000</td>\n",
       "      <td>0.416125</td>\n",
       "      <td>0.215834</td>\n",
       "      <td>1.442362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c0000</td>\n",
       "      <td>0.228299</td>\n",
       "      <td>0.833621</td>\n",
       "      <td>2.295887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c9999</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>2.017855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c9999</td>\n",
       "      <td>0.466480</td>\n",
       "      <td>0.729859</td>\n",
       "      <td>2.204831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c9999</td>\n",
       "      <td>0.187594</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>1.350019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c9999</td>\n",
       "      <td>0.768211</td>\n",
       "      <td>0.467250</td>\n",
       "      <td>1.366468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c9999</td>\n",
       "      <td>0.557691</td>\n",
       "      <td>0.237854</td>\n",
       "      <td>1.481375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key        x1        x2         y\n",
       "0   c0000  0.320411  0.914019  1.758490\n",
       "1   c0000  0.421961  0.000717  1.095975\n",
       "2   c0000  0.472938  0.205749  1.981890\n",
       "3   c0000  0.416125  0.215834  1.442362\n",
       "4   c0000  0.228299  0.833621  2.295887\n",
       "..    ...       ...       ...       ...\n",
       "5   c9999  0.708642  0.019811  2.017855\n",
       "6   c9999  0.466480  0.729859  2.204831\n",
       "7   c9999  0.187594  0.019971  1.350019\n",
       "8   c9999  0.768211  0.467250  1.366468\n",
       "9   c9999  0.557691  0.237854  1.481375\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本一\n",
    "\n",
    "最直接的写法是 groupby.apply："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.1 s ± 659 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def ols1(d):\n",
    "    X = sm.add_constant(d[[\"x1\", \"x2\"]])\n",
    "    y = d[\"y\"]\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    return res.params\n",
    "\n",
    "%timeit df.groupby([\"key\"]).apply(ols1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计耗时 14.8s 左右：\n",
    "\n",
    "```\n",
    "14.8 s ± 249 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本二\n",
    "\n",
    "考虑到上面数据通过 apply 返回合并为 DataFrame 会比较慢，做一下改版："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04 s ± 99.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def ols2(d):\n",
    "    X = sm.add_constant(d[[\"x1\", \"x2\"]].to_numpy())\n",
    "    y = d[\"y\"].to_numpy()\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    return res.params\n",
    "\n",
    "%timeit df.groupby([\"key\"]).apply(ols2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "耗时统计 5.6s 左右，优化效果很明显：\n",
    "\n",
    "```\n",
    "5.6 s ± 230 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本三\n",
    "\n",
    "众所周知，groupby.apply 并没有并行执行，再写一下并行版本进一步进行优化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed # pip install joblib\n",
    "\n",
    "def ols3(key, d):\n",
    "    X = sm.add_constant(d[[\"x1\", \"x2\"]].to_numpy())\n",
    "    y = d[\"y\"].to_numpy()\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    return np.append([key], res.params)\n",
    "    \n",
    "# %%timeit\n",
    "grouped = df.groupby([\"key\"])\n",
    "results = Parallel(n_jobs=-1)(delayed(ols3)(key, group) for key, group in grouped)\n",
    "results_3_df = pd.DataFrame(results, columns=[\"key\", \"const\", \"x1\", \"x2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "耗时统计 2.1s 左右，又优化一大截：\n",
    "```\n",
    "2.1 s ± 33.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```\n",
    "如果不将结果转换为 DataFrame 是 `1.81s` ：\n",
    "\n",
    "```\n",
    "1.81 s ± 108 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DuckDB 实现\n",
    "\n",
    "最近使用 DudkDB 处理数据比较多，\n",
    "\n",
    "与 Python 语言交互时，我们可以从 python 函数中创建一个 DuckDB 用户定义函数（UDF），这样它就可以在 SQL 查询中使用。\n",
    "\n",
    "这样定义的函数，由数据库调度运行，看下是否能据此优化我们的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本四\n",
    "\n",
    "首先定义一个回归函数，然后注册给 duckdb："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x206ca3e79b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb # pip install duckdb\n",
    "from contextlib import suppress\n",
    "\n",
    "# df_2 = pd.concat([mock(i) for i in range(10000)])\n",
    "\n",
    "\n",
    "def ols4(x: list, y: list) -> list[float]:\n",
    "    X = sm.add_constant(np.array([[r[\"x1\"], r[\"x2\"]] for r in x]))\n",
    "    res = sm.OLS(y, X).fit()\n",
    "    return res.params\n",
    "\n",
    "with suppress(Exception):\n",
    "    duckdb.remove_function(\"ols4\")\n",
    "    duckdb.remove_function(\"ols4\")\n",
    "\n",
    "duckdb.create_function(\"ols4\", ols4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬─────────────────────┬───────────────────────┬────────────────────┐\n",
       "│   key   │         x1          │          x2           │         y          │\n",
       "│ varchar │       double        │        double         │       double       │\n",
       "├─────────┼─────────────────────┼───────────────────────┼────────────────────┤\n",
       "│ c0000   │  0.3204107883503745 │    0.9140187586935561 │ 1.7584898315489523 │\n",
       "│ c0000   │  0.4219612972142287 │ 0.0007167400957338588 │ 1.0959746259667127 │\n",
       "│ c0000   │  0.4729384994108561 │   0.20574929220201954 │  1.981889733870671 │\n",
       "│ c0000   │  0.4161245922765133 │    0.2158336364040867 │ 1.4423616588721528 │\n",
       "│ c0000   │   0.228299346382541 │    0.8336210600307845 │ 2.2958868832363923 │\n",
       "│ c0000   │  0.8873711143592423 │    0.3303355527019023 │ 1.3416064764622262 │\n",
       "│ c0000   │  0.6748109360980198 │    0.0455976433142572 │ 1.6631172022242442 │\n",
       "│ c0000   │  0.9041066077178131 │   0.04387839507289515 │ 1.5771440524066658 │\n",
       "│ c0000   │  0.3077707390241732 │    0.8566586038008007 │ 2.2359768781439984 │\n",
       "│ c0000   │  0.5034898487150499 │    0.8369129765844202 │ 2.0566578491249565 │\n",
       "│   ·     │           ·         │             ·         │          ·         │\n",
       "│   ·     │           ·         │             ·         │          ·         │\n",
       "│   ·     │           ·         │             ·         │          ·         │\n",
       "│ c0999   │  0.7964856859200701 │    0.5888755788878827 │ 1.8444003324705363 │\n",
       "│ c0999   │  0.8172532875224275 │   0.16843622320253804 │ 1.4334458859062194 │\n",
       "│ c0999   │  0.7701975361193849 │    0.2904617509397036 │ 1.8678410636626057 │\n",
       "│ c0999   │  0.2202778006355567 │    0.8500048211481356 │ 1.5895914343837743 │\n",
       "│ c0999   │ 0.47064721404055154 │    0.3564966584694904 │  2.213451728291764 │\n",
       "│ c0999   │  0.9779853091912263 │   0.16596842560571812 │  1.507755837910032 │\n",
       "│ c0999   │   0.775488779779345 │    0.6358074901553894 │ 2.0338766709738425 │\n",
       "│ c0999   │   0.778785902898279 │     0.817083712668555 │ 2.0700990897464626 │\n",
       "│ c0999   │ 0.48294442885533395 │ 0.0002788086308205262 │ 1.3792398216280681 │\n",
       "│ c0999   │  0.6832459686579954 │   0.06344365265319274 │ 1.8892203481063499 │\n",
       "├─────────┴─────────────────────┴───────────────────────┴────────────────────┤\n",
       "│ ? rows (>9999 rows, 20 shown)                                    4 columns │\n",
       "└────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.query(\"select * from df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就可以在 SQL 中直接调用，执行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This relation does not contain a column by the name of 'fetch_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m sql \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith tmp as(\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39m    select key, ols4(list((x1, x2)), list(y)) as coef\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39morder by all\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39m# %timeit duckdb.sql(sql).df() # 运行error ？ .df() error？\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mduckdb.sql(sql).fetch_df() # 运行error ？ .df() error？\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\afire\\.conda\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2454\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2455\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2456\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2458\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m \u001b[39m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\afire\\.conda\\envs\\py310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[0;32m   1184\u001b[0m     number \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m index\n\u001b[1;32m-> 1185\u001b[0m     time_number \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[0;32m   1186\u001b[0m     \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[0;32m   1187\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\afire\\.conda\\envs\\py310\\lib\\site-packages\\IPython\\core\\magics\\execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    171\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[0;32m    172\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[0;32m    174\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: This relation does not contain a column by the name of 'fetch_df'"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "with tmp as(\n",
    "    select key, ols4(list((x1, x2)), list(y)) as coef\n",
    "    from df\n",
    "    group by all\n",
    ")\n",
    "select key, coef[1] as const, coef[2] as x1, coef[3] as x2\n",
    "from tmp\n",
    "order by all\n",
    "\"\"\"\n",
    "duckdb.sql(sql).df()\n",
    "\n",
    "# %timeit duckdb.sql(sql).df() # 运行error ？ .df() error？\n",
    "%timeit duckdb.sql(sql).fetch_df() # 运行error ？ .df() error？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "耗时为 2.9s，看上去还没有上面 Python 并行化版本效率高：\n",
    "\n",
    "```\n",
    "2.9 s ± 26.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本五\n",
    "\n",
    "猜测 *.df() 转 DataFrame 格式耗时比较久，如果不进行格式转换，直接运行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811 µs ± 63.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit duckdb.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "耗时仅有 825 µs，非常 amazing！\n",
    "\n",
    "```\n",
    "825 µs ± 5.98 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版本六\n",
    "\n",
    "注意到上面 SQL 中为 select * from df，我们查询的是 DataFrame。\n",
    "\n",
    "如果我们直接查询的是 DuckDB 的表，应该还会进一步减少耗时。例如将 df 存为表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "create or replace table example as\n",
    "select * from df\n",
    "\"\"\"\n",
    "duckdb.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，重新执行计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 µs ± 2.48 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "with tmp as (\n",
    "    select key, ols4(list((x1, x2)), list(y)) as coef\n",
    "    from example\n",
    "    group by all\n",
    ")\n",
    "select key, coef[1] as const, coef[2] as x1, coef[3] as x2\n",
    "from tmp\n",
    "order by all\n",
    "\"\"\"\n",
    "%timeit duckdb.sql(sql)\n",
    "# duckdb.sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计耗时仅有 131 µs：\n",
    "\n",
    "```\n",
    "131 µs ± 1.46 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顾下一路下来的优化：\n",
    "\n",
    "版本\t| 说明\t| 耗时\n",
    "---|---|---\n",
    "版本一\t| Pandas 直接 apply\t| 14.8s\n",
    "版本二\t|numpy 优化\t\t| 5.6s\n",
    "版本三\t|joblib 并行\t\t| 2.1s\n",
    "版本四\t|DuckDB UDF 处理和输出 DataFrame\t\t| 2.9s\n",
    "版本五\t|DuckDB UDF 处理 DataFrame\t\t| 825µs\n",
    "版本六\t|DuckDB UDF 直接处理表\t\t| 131µs\n",
    "\n",
    "其实上述比较并不严谨，它们输出的结果格式并不统一（numpy/dataframe/duckdb 等），\n",
    "\n",
    "而不同技术栈有不同契合的输入/输出上下文。\n",
    "\n",
    "可以看到版本四相比版本三其实还要慢一点，测试用例只是保证了其在本技术栈上代码和逻辑上都尽可能简洁直观。\n",
    "\n",
    "对于版本六，如果将结果输出为 DuckDB 的表，加上 IO，也需要花费 2s 多，\n",
    "如果使用 CTE，直接使用计算结果，进一步计算诸如最大系数之类的，耗时会更少：\n",
    "\n",
    "\n",
    "```sql\n",
    "with tmp as (\n",
    "    select key, ols4(list((x1, x2)), list(y)) as coef\n",
    "    from example\n",
    "    group by all\n",
    ")\n",
    "select max(coef[1]) from tmp\n",
    "```\n",
    "\n",
    "因此，我们也不用标题党的说，通过 DuckDB 将 Pandas 代码优化了多少多少倍。\n",
    "\n",
    "实践上，如果我们上下游数据处理都是通过 DuckDB，对于复杂的运算在 SQL 中不好实现，\n",
    "\n",
    "我们可以通过 Python 来实现，这样我们就可以利用 DuckDB 高性能的同时，也能使用 Python 丰富的生态，达到两者兼顾的目的，大大提升我们分析数据的效率。\n",
    "\n",
    "即使你日常中更多的是使用 Pandas/Polars 等，上例中看到 DuckDB 和 DataFrame 交互是非常方便的，也可以借用 DuckDB 来优化我们的代码，算是一种不错的选择。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
